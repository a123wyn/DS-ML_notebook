{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 数据读取分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "titanic=pd.read_csv(\"titanic/train.csv\")\n",
    "# 对数据进行一个大概统计，查看缺失值或是无意义值等\n",
    "titanic.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.361582</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>13.019697</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  891.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.361582    0.523008   \n",
       "std     257.353842    0.486592    0.836071   13.019697    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   22.000000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   35.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 发现age字段缺失，进行缺失值处理，填充中位数\n",
    "titanic['Age']=titanic['Age'].fillna(titanic['Age'].median())\n",
    "titanic.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['male' 'female']\n",
      "['S' 'C' 'Q' nan]\n"
     ]
    }
   ],
   "source": [
    "# 将非数值型数据进行量化\n",
    "\n",
    "# Sex量化\n",
    "print(titanic['Sex'].unique())\n",
    "titanic.loc[titanic['Sex']=='male','Sex']=0\n",
    "titanic.loc[titanic['Sex']=='female','Sex']=1\n",
    "\n",
    "# Embarked进行量化\n",
    "print(titanic['Embarked'].unique())\n",
    "titanic.loc[titanic['Embarked']=='S','Embarked']=0\n",
    "titanic.loc[titanic['Embarked']=='C','Embarked']=1\n",
    "titanic.loc[titanic['Embarked']=='Q','Embarked']=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "# 发现Embarked有缺失值，决定用较多的数量来填充，通过统计得出是0\n",
    "max_Embarked=titanic.groupby('Embarked').count().sort_values('PassengerId',ascending=False).index[0]\n",
    "print(max_Embarked)\n",
    "titanic['Embarked']=titanic['Embarked'].fillna(max_Embarked)\n",
    "print(titanic['Embarked'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 线性回归模型建立"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用线性回归，以及使用交叉验证集来调参\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 选出的特征值\n",
    "features=['Pclass','Sex','Age','SibSp','Parch','Fare','Embarked']\n",
    "\n",
    "# 使用线性模型\n",
    "LR=LinearRegression()\n",
    "\n",
    "# 使用三次交叉验证，分成三个部分，kf有共三组数据，不随机打乱\n",
    "kf=KFold(n_splits=3, shuffle=False)\n",
    "\n",
    "predictions=[]\n",
    "for train,test in kf.split(titanic):\n",
    "    # 获取训练集及标记\n",
    "    train_predictors=titanic[features].iloc[train,:]\n",
    "    train_target=titanic['Survived'].iloc[train]\n",
    "    # 用线性回归模型拟合及预测\n",
    "    LR.fit(train_predictors,train_target)\n",
    "    test_predictions=LR.predict(titanic[features].iloc[test,:])\n",
    "    predictions.append(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7833894500561167\n"
     ]
    }
   ],
   "source": [
    "# 将测试结果拼接完成\n",
    "predictions=np.concatenate(predictions,axis=0)\n",
    "\n",
    "predictions[predictions>0.5]=1\n",
    "predictions[predictions<0.5]=0\n",
    "accuracy=len(predictions[predictions==titanic['Survived']])/len(predictions)\n",
    "print(accuracy)\n",
    "# 线性回归的精度不太好"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Logistic回归模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7957351290684623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# 用Logistic回归方式\n",
    "LogR=LogisticRegression(random_state=1)\n",
    "# 通过交叉验证集平均来估计总体性能\n",
    "scores=cross_val_score(LogR,titanic[features],titanic['Survived'],cv=3)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 随机森林模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7856341189674523\n"
     ]
    }
   ],
   "source": [
    "# 随机森林模型\n",
    "features=['Pclass','Sex','Age','SibSp','Parch','Fare','Embarked']\n",
    "RF=RandomForestClassifier(random_state=1,n_estimators=10,min_samples_split=2,min_samples_leaf=1)\n",
    "kf=KFold(n_splits=3, shuffle=False)\n",
    "scores=cross_val_score(RF,titanic[features],titanic['Survived'],cv=kf)\n",
    "\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n_estimators ： integer, optional (default=10) 整数，可选择(默认值为10)。\n",
    "### ★ 弱学习器的最大迭代次数，太小，容易欠拟合，太大，又容易过拟合。\n",
    "### criterion: string, optional (default=”gini”) 字符串，可选择(默认值为“gini”)。\n",
    "### ★衡量分裂质量的性能函数，默认是基尼不纯度，熵达到峰值的过程要相对慢一些。\n",
    "### max_depth : integer or None, optional (default=None) 整数或者无值，可选的（默认为None）\n",
    "### ★ 决策树最大深度，如果模型样本量多，特征也多的情况下，推荐限制这个最大深度，具体的取值取决于数据的分布。常用的可以取值10-100之间。\n",
    "### min_samples_split: int, float, optional (default=2) 整数，浮点数，可选的（默认值为2）\n",
    "### ★ 内部节点再划分所需最小样本数。如果某节点的样本数少于，则不会继续再尝试选择最优特征来进行划分。 默认是2.如果样本量不大，不需要管这个值。如果样本量数量级非常大，则推荐增大这个值。\n",
    "### min_samples_leaf: int, float, optional (default=1) 整数，浮点数，可选的（默认值为1）\n",
    "### ★ 叶子节点最少样本数。如果样本量数量级非常大，则推荐增大这个值。\n",
    "### min_weight_fraction_leaf: float, optional (default=0.) 浮点数，可选的（默认值是0.0）\n",
    "### ★叶子节点最小的样本权重和。就是不考虑权重问题。一般来说，如果我们有较多样本有缺失值，或者分类树样本的分布类别偏差很大，就会引入样本权重，这时我们就要注意这个值了。\n",
    "### max_features ：int, float, string or None, optional (default=”auto”) 整数，浮点数，字符串或者无值，可选的（默认值为\"auto\"）\n",
    "### ★ 最大特征数\n",
    "### max_leaf_nodes : int or None, optional (default=None) 整数或者无值,可选的（默认值为None）\n",
    "### ★最大叶子节点数。限制最大叶子节点数，可以防止过拟合。以最优的方法使用max_leaf_nodes来生长树。最好的节点被定义为不纯度上的相对减少。如果为None,那么不限制叶子节点的数量。\n",
    "### min_impurity_decrease : float, optional (default=0.) 浮点数，可选的（默认值为0）\n",
    "### ★如果节点的分裂导致的不纯度的下降程度大于或者等于这个节点的值，那么这个节点将会被分裂。\n",
    "### min_impurity_split: float, 浮点数\n",
    "### ★节点划分最小不纯度。\n",
    "### bootstrap : boolean, optional (default=True) 布尔值，可选的（默认值为True）\n",
    "### ★建立决策树时，是否使用有放回抽样。\n",
    "### oob_score : bool (default=False) bool，（默认值为False）\n",
    "### ★ 建议用True，袋外分数反应了一个模型拟合后的泛化能力。\n",
    "### n_jobs: integer, optional (default=1) 整数，可选的（默认值为1）\n",
    "### ★用于拟合和预测的并行运行的工作（作业）数量。如果值为-1，那么工作数量被设置为核的数量\n",
    "### random_state: int, RandomState instance or None, optional (default=None) 整数，RandomState实例，或者为None,可选（默认值为None）\n",
    "### ★是随机数生成器使用的种子; 如果是RandomState实例，random_state就是随机数生成器；如果为None，则随机数生成器是np.random使用的RandomState实例。\n",
    "### verbose : int, optional (default=0) 整数，可选的（默认值为0）\n",
    "### ★控制决策树建立过程的冗余度。\n",
    "### warm_start : bool, optional (default=False) 布尔值，可选的（默认值为False）\n",
    "### ★当被设置为True时，重新使用之前呼叫的解决方案，用来给全体拟合和添加更多的估计器，反之，仅仅只是为了拟合一个全新的森林。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8103254769921436\n"
     ]
    }
   ],
   "source": [
    "RF=RandomForestClassifier(random_state=1,n_estimators=10,min_samples_split=4,min_samples_leaf=2)\n",
    "kf=KFold(n_splits=3, shuffle=False)\n",
    "scores=cross_val_score(RF,titanic[features],titanic['Survived'],cv=kf)\n",
    "\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 简单特征生成\n",
    "titanic['family size']=titanic['SibSp']+titanic['Parch']\n",
    "# 名字长度\n",
    "titanic['NameLength']=titanic['Name'].apply(lambda x:len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# 名字中的尊称提取\n",
    "def get_title(name):\n",
    "    title_search=re.search('([A-Za-z]+)\\.',name)\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\"\n",
    "\n",
    "titles=titanic['Name'].apply(get_title)\n",
    "\n",
    "title_mapping={'Mr':1,'Miss':2,'Mrs':3,'Master':4,'Dr':5,'Rev':6,'Major':7,'Col':8,'Mlle':9,'Countess':10,'Ms':11,'Lady':12,'Jonkheer':13,'Don':14,'Mme':15,'Capt':16,'Sir':17}\n",
    "for k,v in title_mapping.items():\n",
    "    titles[titles==k]=v\n",
    "\n",
    "titanic['titles']=titles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest,f_classif\n",
    "import matplotlib.pyplot as plt\n",
    "features=['Pclass','Sex','Age','SibSp','Parch','Fare','Embarked','family size','NameLength','titles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "selector=SelectKBest(f_classif,k=5)\n",
    "selector.fit(titanic[features],titanic['Survived'])\n",
    "scores=-np.log10(selector.pvalues_)\n",
    "plt.bar(range(len(features)),scores)\n",
    "plt.xticks(range(len(features)),features,rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=['Pclass','Sex','Fare','NameLength','titles']\n",
    "RF=RandomForestClassifier(random_state=1,n_estimators=50,min_samples_split=8,min_samples_leaf=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms=[\n",
    "    [GradientBoostingClassifier(random_state=1,n_estimators=25,max_depth=3),['Pclass',]]\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
